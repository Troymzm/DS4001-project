# Mentality of designing/设计思路

## 条件生成方案

考虑到重新构建一个新模型所费精力过多，我们选择直接在任务一已经优化好的模型基础的上加以修改，主要是在encode和decode模块里想办法嵌入labels：

1. **数据集给出的labels的特征**：
   - 图像内容为0~9的数字，意味着图像可以按照数字大小分为10类，即有效标签只有10种。
2. **标签嵌入方式**：
   - 编码器部分，将编码器输出的隐藏特征与标签的 one-hot 向量拼接，然后再送入均值（mu）和对数方差（log_var）输出层。这样，编码器在学习潜在空间分布时会考虑标签信息，使同一类别的样本在潜在空间中更接近。
   - 解码器部分，在解码器输入时，将采样得到的潜在向量 z 与标签的 one-hot 向量拼接，然后输入解码器。这样，解码器能够根据 z 和标签信息生成指定类别的样本。
3. **标签结构设计**：
   - 最初的构想是专门构建一个模块，把输入的labels转换为需要的形式，但由于训练和测试代码中label格式不一，这一模块实现过于复杂，便改为直接在使用labels的地方进行专门的修改。
   - 编码器中，依据data_utils.py里对DataLoader的设计，输入的images和labels出自同一个batch，共用一个batch_size。又考虑到原始的encode函数输出的h的结构为[batch_size, hidden_dim]，那么我们便也可以对labels做处理，使其与h具有相同结构[batch_size, num_classes]，恰好one-hot向量格式可以满足。结构一致后，便可以进行拼接了。
   - 译码器中，在训练代码中，z和x格式一致，可以正常训练。但在inference.py中，z的输入里，batch_size也即第0维值为1，同时输入设备的labels仅为一维张量，故而需对照z对labels做专门处理。

### 可行性理论分析

在VAE（变分自编码器）中引入labels嵌入（如one-hot编码后拼接到隐变量或特征向量）属于条件VAE（Conditional VAE, CVAE）的典型做法。其理论基础和有效性可以从以下几个方面说明：

#### 条件概率建模

普通VAE建模的是 $p(x)$，即无条件的生成分布。而CVAE建模的是 $p(x|y)$，即在给定标签 $y$ 的条件下生成数据 $x$。这使得模型能够学习到不同类别数据的分布特征，从而实现有条件的生成。

CVAE的目标是最大化条件下的边缘似然：
$$
\log p(x|y) \geq \mathbb{E}_{q(z|x,y)}[\log p(x|z,y)] - D_{KL}(q(z|x,y) \| p(z|y))
$$
其中 $y$ 是标签，$z$ 是隐变量。

#### 标签信息的注入

通过将标签one-hot编码后与特征或隐变量拼接，模型的编码器和解码器都能直接获得类别信息。这样：
- 编码器 $q(z|x,y)$ 能更好地根据类别分布对 $z$ 进行建模。
- 解码器 $p(x|z,y)$ 能更好地根据 $z$ 和类别 $y$ 还原出对应类别的样本。

#### 理论推导

假设 $y$ 是类别标签，$z$ 是隐变量，$x$ 是观测数据。CVAE的生成过程为：
1. 采样 $z \sim p(z|y)$
2. 生成 $x \sim p(x|z, y)$

训练时，变分下界为：
$$
\mathcal{L} = \mathbb{E}_{q(z|x,y)}[\log p(x|z,y)] - D_{KL}(q(z|x,y) \| p(z|y))
$$
通过拼接one-hot标签，$q(z|x,y)$ 和 $p(x|z,y)$ 都能直接感知类别信息，优化上述目标更容易。

#### 为什么有效果

- **类别信息显式注入**：拼接one-hot标签后，模型能区分不同类别的分布，避免不同类别的样本在隐空间混淆。
- **提升生成质量**：在解码阶段，标签信息帮助模型生成更符合指定类别的样本。
- **理论上更强的表达能力**：条件分布 $p(x|y)$ 比无条件分布 $p(x)$ 更容易建模，模型收敛更快，生成样本更准确。

# Experiment/实验

## 使用CVAE完成MNIST图像生成

### Setting/设置

我们直接使用原VAE最有效的超参数组合进行训练，效果异常良好。在屡次测试后，我们并不那么惊讶地发现label的引入并没有对模型带来想象中的巨大的变化，消融实验的结果和原始VAE差别不大。故而在后面的深入分析中，我们只对异常现象进行了列举。

```bash
--task Genwithlabel \
--epochs 50 \
--batch_size 1024 \
--lr 5e-3 \
--latent_dim 20 \
--var 0.25
```


### Results/结果

1. **测试结果**：

   - ssim: 0.8591127103661814
   - mse: 0.012526811785498535
   - fid: 2.4119390535928966
   - score: 29.275927968488208


### Indepth analysis/深入分析

#### 1. 网络架构消融实验

1. **卷积层数量的影响**：

   其他一致的参数

   ```
   --epochs 50 \
   --batch_size 1024 \
   --lr 5e-3 \
   --latent_dim 20 \
   --var 0.25
   ```

   | 卷积层数量  | ssim                   | mse                      | fid                    |
   | ---------- | ---------------------- | -----------------------  | ---------------------- |
   | 2          | 0.8592167606420389     | 0.012593720543119205     | 3.018448287036226      |  
   | **3**      | **0.8591127103661814** | **0.012526811785498535** | **2.4119390535928966** |
   | 4          | loss 爆炸              | loss 爆炸                | loss 爆炸               |

   由实验数据可知：卷积层数量在CVAE下对ssim和mse的影响很小，但对fid影响大，应是卷积层数量不足会导致标签模型的特征提取能力有限，难以捕捉到类别间的细微差异和复杂分布，导致生成样本的分布与真实样本差异较大，从而使FID变差。
   考虑到卷积层数量应是重要的影响因素，我仍做数据对比。可以看出，加入了labels的CVAE受其影响趋势与原始VAE一致，我便不多加阐述。后续和这一结果类似者，我便不加提及。

2. **潜在空间维度的异常**：

   其他一致的参数

   ```
   --epochs 50 \
   --batch_size 1024 \
   --lr 5e-3 \
   --var 0.25
   ```

   | latent_dim | ssim                   | mse                      | fid                    |
   | ---------- | ---------------------- | ------------------------ | ---------------------- |
   | 10         | 0.8471395289192581     | 0.013516769603919988     | 2.287528376585291      |
   | **20**     | **0.8591127103661814** | **0.012526811785498535** | **2.4119390535928966** |
   | 30         | loss 爆炸              | loss 爆炸                | loss 爆炸               |

   在原本的实验结果中，潜在空间维度对模型性能影响并不显著，但加入labels后，在计算中等效为40的latent_dim便会导致模型无法正常运行，可能原因是由于编码器输出的均值和方差参数数量也随之增多，KL散度项的总和变大，导致loss整体变大甚至爆炸，模型难以收敛。同时，高维下，$\exp(\log \sigma^2)$、$\mu^2$等项更容易出现极端值，导致梯度爆炸或loss为NaN。

#### 2. 训练策略分析

1. **以学习率调试为例的fid值特殊变化趋势分析**：
   
   其他一致的参数
   
   ```
   --epochs 50 \
   --batch_size 1024 \
   --latent_dim 20 \
   --var 0.25
   ```
   
   | learning_rate | ssim                   | mse                      | fid                    |
   | ------------- | ---------------------- | ------------------------ | ---------------------- |
   | 2e-3          | 0.8631752044843571     | 0.012150775533742872     | 2.583163718440153      |
   | **5e-3**      | **0.8591127103661814** | **0.012526811785498535** | **2.4119390535928966** |
   | 6e-3          | 0.8545897460096794     | 0.012805900020792613     | 2.4579384168273726     |
   
   fid的数值变动似乎一直都不是很合群，结合上面的latent_dim和卷积层数量的数据进行对比，你会发现，每当fid的变动趋势往往是和ssim和mse的趋势是不同的。仅看前两项，学习率值明显应当向下取值，但是较低的学习率却带来了fid值的提高，并经助教给出的公式计算后得到更低的分数。
   对于其导致原因，我们的看法是：ssim和mse只反映单张图片的还原质量，而fid反映生成样本整体分布与真实分布的距离，对模型特征提取和生成能力更敏感。标准VAE的缺陷恰恰在于其无法控制生成样本的具体属性，而标签的加入便是为了使精确生成成为可能。对于精确性的要求进一步导致了对模型特征提取能力的更高要求，这也是fid指数的来源。这样看来，fid的优劣在条件生成任务的语境下更加重要。